# XndApp/Services/pipeline_logic.py

import os
import numpy as np
import cv2
from django.conf import settings
from typing import Dict, List, Any
from XndApp.apps import SrmappConfig
from google.cloud import vision
import re
from datetime import date
import math
from gensim.models import Word2Vec

# ì˜ì–‘ì„±ë¶„ í‚¤ì›Œë“œ (ìœ í†µê¸°í•œ/ì‹ì¬ë£Œëª… ì¸ì‹ì—ì„œ ì œì™¸)
NUTRITION_KEYWORDS = [
    'ë‚˜íŠ¸ë¥¨', 'íƒ„ìˆ˜í™”ë¬¼', 'ë‹¹ë¥˜', 'ì§€ë°©', 'íŠ¸ëœìŠ¤ì§€ë°©', 'í¬í™”ì§€ë°©',
    'ì½œë ˆìŠ¤í…Œë¡¤', 'ë‹¨ë°±ì§ˆ', 'ì¹¼ìŠ˜', 'ì—´ëŸ‰', 'g', 'mg', 'kcal', '%'
]

# 1. ë©”ì¸ íŒŒì´í”„ë¼ì¸ í•¨ìˆ˜
def process_image_pipeline(user_id: int, image_path: str) -> Dict[str, Any]:
    if not os.path.exists(image_path):
        return {"error": "Image file not found"}

    result_data = {
        'user_id': user_id,
        'stored_at': date.today(),
        'ingredient_name': '',
        'category_yolo': None,
        'product_name_ocr': None,
        'expiry_date': None,
        'expiry_date_status': 'NOT_FOUND',
        'ingredient_pic': image_path,
    }

    yolo_result = run_yolo_detection(image_path)  # 1. YOLO ì‹¤í–‰: BB ì¢Œí‘œ ë° ì‹ì¬ë£Œ ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ

    if yolo_result is None:  # YOLO ì¸ì‹ ì‹¤íŒ¨ì‹œ ì´ë¯¸ì§€ í¬ë¡­ X
        yolo_result = {
            'bounding_box': [0, 0, 0, 0],
            'category_name': 'FALLBACK_MODE',
            'fallback_mode': True  # Fallback ëª¨ë“œ í”Œë˜ê·¸
        }

    ocr_raw_output = run_ocr(image_path, yolo_result)     # 2. OCR ì‹¤í–‰: ì´ë¯¸ì§€ í¬ë¡­ í›„, í´ë¼ìš°ë“œ API í˜¸ì¶œ ë° ì›ë³¸ í…ìŠ¤íŠ¸ ìˆ˜ì‹ 
    ocr_info = extract_ocr_info(ocr_raw_output)           # 3. í…ìŠ¤íŠ¸ ì •ë³´ ì¶”ì¶œ: ì›ë³¸ í…ìŠ¤íŠ¸ì—ì„œ ë‚ ì§œ, ì œí’ˆëª… ë“±ì„ ì •ê·œì‹ìœ¼ë¡œ ì¶”ì¶œ
    final_data = integrate_results(result_data, yolo_result, ocr_info, ocr_raw_output)     # 4. ê²°ê³¼ í†µí•©: YOLOì™€ OCR ê²°ê³¼ë¥¼ ë³‘í•©í•˜ê³  ì‹ ë¢°ë„ì— ë”°ë¼ ë¶„ê¸° ì²˜ë¦¬

    return final_data

# 2. â‘¡ YOLO ëª¨ë¸ ì ìš© (ê°ì²´ íƒì§€)
def run_yolo_detection(image_path: str) -> Dict[str, Any]:
    model = SrmappConfig.yolo_model

    if model is None:
        return None  # ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ ì‹œ None ë°˜í™˜

    try:
        results = model.predict(source=image_path, conf=0.25, iou=0.5, verbose=True)

        if not results or not results[0].boxes:
            return None  # íƒì§€ ì‹¤íŒ¨ ì‹œ None ë°˜í™˜

        ## ê°ì²´ ì¸ì‹ ì„±ê³µ ì‹œ
        box = results[0].boxes[0]
        xmin, ymin, xmax, ymax = map(int, box.xyxy[0].tolist())
        confidence = float(box.conf[0])
        class_index = int(box.cls[0])
        category_name = model.names[class_index]

        print(f"DEBUG: Extracted YOLO Confidence: {confidence}")

        ## - YOLO ê²°ê³¼ ì‹œê°í™” ë° ì €ì¥
        img_array = np.fromfile(image_path, np.uint8)
        image_cv = cv2.imdecode(img_array, cv2.IMREAD_COLOR)
        cv2.rectangle(image_cv, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)
        text = f"{category_name}: {confidence:.2f}"
        cv2.putText(image_cv, text, (xmin, ymin - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)
        base_name = os.path.splitext(os.path.basename(image_path))[0]
        output_filename = f"{base_name}_yolo_checked.jpg"
        output_path = settings.MEDIA_ROOT / 'stored_images_yolo' / output_filename
        os.makedirs(settings.MEDIA_ROOT / 'stored_images_yolo', exist_ok=True)

        is_success, buffer = cv2.imencode(".jpg", image_cv)
        if is_success:
            buffer.tofile(output_path)
            print(f"âœ… YOLO visualization saved to: {output_path}")

        return {
            'category_name': category_name,
            'confidence': confidence,
            'bounding_box': [xmin, ymin, xmax, ymax],
        }
        ## -

    except Exception as e:
        print(f"YOLO detection error: {e}")
        return None  # ì˜ˆì™¸ ë°œìƒ ì‹œ None ë°˜í™˜


# 3. â‘¢ OCR ëª¨ë¸ ì ìš© (ì´ë¯¸ì§€ í¬ë¡­ ë° í…ìŠ¤íŠ¸ ì¸ì‹)
def run_ocr(image_path: str, yolo_result: Dict[str, Any]) -> Dict[str, Any]:

    word_blocks: List[Dict[str, Any]] = []

    try:  #êµ¬ê¸€ API ì¸ì¦ ì„¤ì •
        os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = str(settings.GOOGLE_APPLICATION_CREDENTIALS)
    except AttributeError:
        return {'raw_text': "Error: GOOGLE_APPLICATION_CREDENTIALS is not set in settings.py",
                'word_blocks': word_blocks}

    try:
        img_array = np.fromfile(image_path, np.uint8)
        image_cv = cv2.imdecode(img_array, cv2.IMREAD_COLOR)
    except Exception as e:
        return {"raw_text": f"Error: Image read failed. {e}", 'word_blocks': word_blocks}


    if yolo_result.get('fallback_mode'): #Fallback ëª¨ë“œ : ì´ë¯¸ì§€ ì „ì²´ ì‚¬ìš©
        height, width = image_cv.shape[:2]
        xmin, ymin, xmax, ymax = 0, 0, width, height
    else: # YOLOê°€ íƒì§€í•œ BBë°•ìŠ¤ ì‚¬ìš©
        bounding_box = yolo_result.get('bounding_box', [0, 0, 0, 0])
        xmin, ymin, xmax, ymax = bounding_box

    base_name = os.path.splitext(os.path.basename(image_path))[0]
    ocr_output_dir = settings.MEDIA_ROOT / 'stored_images_ocr'
    os.makedirs(ocr_output_dir, exist_ok=True)

    try:
        cropped_image = image_cv[ymin:ymax, xmin:xmax] #OpenCV ì´ë¯¸ì§€ ì²˜ë¦¬

        is_success, buffer = cv2.imencode(".png", cropped_image) # Cropëœ ì´ë¯¸ì§€ ì¸ì½”ë”©
        if not is_success:
            return {'raw_text': "Error: Image encoding failed", 'word_blocks': word_blocks}

        image_bytes = buffer.tobytes()

        client = vision.ImageAnnotatorClient()         # Vision API í˜¸ì¶œ
        image = vision.Image(content=image_bytes)      # ë°ì´í„° ì¶”ì¶œ

        image_context = vision.ImageContext(language_hints=["ko"])

        response = client.annotate_image(
            request={
                'image': image,
                'features': [{'type_': vision.Feature.Type.DOCUMENT_TEXT_DETECTION}],
                'image_context': image_context
            }
        )

        raw_text = "" # OCRë¡œ ì½ì€ ëª¨ë“  í…ìŠ¤íŠ¸ (ë””ë²„ê¹…ìš©)
        if response.full_text_annotation:
            raw_text = response.full_text_annotation.text

            document = response.full_text_annotation
            for page in document.pages:
                for block in page.blocks:
                    for paragraph in block.paragraphs:
                        for word in paragraph.words:
                            word_text = ''.join([symbol.text for symbol in word.symbols])
                            word_blocks.append({
                                'text': word_text,
                                'confidence': word.confidence,
                                'bounds': [(v.x, v.y) for v in word.bounding_box.vertices]
                            })

            ## - OCR ì‹œê°í™”
            ocr_bb_image = cropped_image.copy()
            for block_data in word_blocks:
                bounds = block_data['bounds']
                x1, y1 = bounds[0]
                x2, y2 = bounds[2]

                cv2.rectangle(ocr_bb_image, (x1, y1), (x2, y2), (0, 165, 255), 1)
                cv2.putText(ocr_bb_image, block_data['text'], (x1, y1 - 2),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.35, (255, 255, 255), 1)

            ocr_bb_filename = f"{base_name}_ocr_bb_checked.jpg"
            ocr_bb_path = ocr_output_dir / ocr_bb_filename

            is_success_bb, buffer_bb = cv2.imencode(".jpg", ocr_bb_image)
            if is_success_bb:
                buffer_bb.tofile(ocr_bb_path)
                print(f"âœ… OCR BB visualization saved to: {ocr_bb_path}")

            return {'raw_text': raw_text, 'word_blocks': word_blocks}
            ## -

        return {'raw_text': '', 'word_blocks': word_blocks}

    except Exception as e:
        print(f"OCR API or Image processing error: {e}")
        return {"raw_text": f"OCR API or Processing error: {e}", 'word_blocks': word_blocks}

# â‘£ ì •ë³´ ì¶”ì¶œ ë° ê°€ê³µ

# í…ìŠ¤íŠ¸ ë¸”ë¡ ì‚¬ì´ì˜ ê±°ë¦¬ ê³„ì‚° (ë‹¨ì–´ - ìˆ«ì)
def get_center(bounds: List[tuple]) -> tuple:
    x_coords = [v[0] for v in bounds]
    y_coords = [v[1] for v in bounds]
    center_x = sum(x_coords) / len(x_coords)
    center_y = sum(y_coords) / len(y_coords)
    return (center_x, center_y)

def calculate_distance(block1: Dict, block2: Dict) -> float:
    center1 = get_center(block1['bounds'])
    center2 = get_center(block2['bounds'])
    return math.sqrt((center1[0] - center2[0]) ** 2 + (center1[1] - center2[1]) ** 2)

# 4-1. ìœ í†µê¸°í•œ íŒ¨í„´ ì„¤ì •
DATE_PATTERNS = [
    r'(?:ì†Œë¹„ê¸°í•œ|ìœ í†µê¸°í•œ)\s*[:]?\s*(\d{4})[ë…„./-]\s*(\d{1,2})[ì›”./-]\s*(\d{1,2})[ì¼]?(?:\s+\d{2}:\d{2}(?::\d{2})?)?[.]?', #ì†Œë¹„/ìœ í†µê¸°í•œ : YYYYë…„ MMì›” DDì¼
    r'(\d{4})ë…„\s*(\d{1,2})ì›”\s*(\d{1,2})ì¼(?:\s+\d{2}:\d{2}(?::\d{2})?)?[.]?',  # YYYYë…„ MMì›” DDì¼
    r'(\d{2})ë…„\s*(\d{1,2})ì›”\s*(\d{1,2})ì¼(?:\s+\d{2}:\d{2}(?::\d{2})?)?[.]?',  # YYë…„ MMì›” DDì¼
    r'(\d{4})[ë…„./-]\s*(\d{1,2})[ì›”./-]\s*(\d{1,2})[ì¼]?\s*ê¹Œì§€(?:\s+\d{2}:\d{2}(?::\d{2})?)?[.]?', #YYYYë…„ MMì›” DDì¼ê¹Œì§€
    r'(\d{4})[./-]([01]?\d)[./-]([0-3]?\d)(?:\s+\d{2}:\d{2}(?::\d{2})?)?[.]?',  # YYYY.MM.DD
    r'(\d{2})[./-]([01]?\d)[./-]([0-3]?\d)(?:\s+\d{2}:\d{2}(?::\d{2})?)?[.]?',  # YY.MM.DD
    r'(\d{4})(\d{2})(\d{2})(?:\s+\d{2}:\d{2}(?::\d{2})?)?[.]?',                 # YYYYMMDD
    r'(\d{2})(\d{2})(\d{2})(?:\s+\d{2}:\d{2}(?::\d{2})?)?[.]?',                 # YYMMDD
    r'([01]?\d)[./]([0-3]?\d)[.]?'                                              # MM.DD
]

# 4-2. ìœ í†µê¸°í•œ í…ìŠ¤íŠ¸ íƒì§€
def extract_ocr_info(ocr_raw_output: Dict[str, Any]) -> Dict[str, Any]:
    raw_text = ocr_raw_output.get('raw_text', '')
    word_blocks = ocr_raw_output.get('word_blocks', [])

    INDICATOR_KEYWORDS = ['ê¹Œì§€', 'ê¸°í•œ', 'ìœ í†µ', 'ì†Œë¹„', 'ìœ í†µê¸°í•œ', 'ì†Œë¹„ê¸°í•œ'] # ìœ í†µê¸°í•œ í‚¤ì›Œë“œ (ìœ í†µê¸°í•œ ìœ í˜• ì‹ ë¢°ë„ 1.0 ë¶€ì—¬)

    found_dates_info = []
    found_keywords_info = []

    for block in word_blocks: # ë‚ ì§œ í›„ë³´ ë° í‚¤ì›Œë“œ ìˆ˜ì§‘
        if any(keyword in block['text'] for keyword in INDICATOR_KEYWORDS):
            found_keywords_info.append(block)

        for pattern in DATE_PATTERNS:
            match = re.search(pattern, block['text'])
            if match:
                date_parts = list(match.groups())
                try:
                    parsed_date = None
                    if len(date_parts) == 3:
                        year, month, day = map(int, date_parts)
                        if year < 100: year += 2000
                        parsed_date = date(year, month, day)
                    elif len(date_parts) == 2:
                        month, day = map(int, date_parts)
                        today = date.today()
                        current_year_date = date(today.year, month, day)
                        parsed_date = date(today.year + 1, month,
                                           day) if current_year_date < today else current_year_date

                    if parsed_date and 2000 <= parsed_date.year <= 2999:
                        found_dates_info.append((parsed_date, block))
                        break
                except ValueError:
                    continue

    best_date = None
    recognition_confidence = 0.0
    type_confidence = 0.5
    filtered_word_blocks = []

    if found_dates_info:
        sorted_dates = sorted(found_dates_info, key=lambda item: item[0], reverse=True)

        for candidate_date, date_block in sorted_dates:
            is_nutrition_info = False
            text_height = abs(date_block['bounds'][0][1] - date_block['bounds'][2][1])
            SEARCH_RADIUS = text_height * 3  # ë‚ ì§œ í…ìŠ¤íŠ¸ ë†’ì´ì˜ 3ë°° ë°˜ê²½ì„ 'ì£¼ë³€'ìœ¼ë¡œ ì •ì˜,

            for block in word_blocks:               # ë‚ ì§œ ê°™ì•„ ë³´ì´ëŠ” ìˆ«ì ì£¼ë³€ì— ì˜ì–‘ì„±ë¶„ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´, ë‚ ì§œê°€ ì•„ë‹Œ ì˜ì–‘ì„±ë¶„ ê°’ìœ¼ë¡œ ì¸ì‹
                if block == date_block: continue

                if any(keyword in block['text'] for keyword in NUTRITION_KEYWORDS):
                    if calculate_distance(date_block, block) < SEARCH_RADIUS:
                        is_nutrition_info = True
                        break
            if is_nutrition_info: # ë‚ ì§œê°€ ì•„ë‹Œ ì˜ì–‘ ì •ë³´ë¡œ íŒë‹¨ë˜ë©´ ë‹¤ìŒ ë‚ ì§œ í›„ë³´ë¡œ
                continue

            best_date = candidate_date   # ìœ íš¨í•œ ë‚ ì§œ í›„ë³´ë¥¼ ì°¾ìœ¼ë©´ ìµœì¢… ì„ íƒ
            best_date_block = date_block
            recognition_confidence = best_date_block['confidence'] # ìœ í†µê¸°í•œìœ¼ë¡œ ì¶”ì •ëœ ê¸€ìì˜ OCR ì¸ì‹ ì‹ ë¢°ë„
            filtered_word_blocks.append(best_date_block)

            min_distance = float('inf')
            closest_keyword_block = None
            if found_keywords_info:
                for keyword_block in found_keywords_info:
                    distance = calculate_distance(date_block, keyword_block)
                    if distance < min_distance:
                        min_distance = distance
                        closest_keyword_block = keyword_block

            DISTANCE_THRESHOLD = text_height * 5 # ìœ í†µê¸°í•œ í‚¤ì›Œë“œ ê¸€ì ë†’ì´ì˜ 5ë°° ì´ë‚´ ê±°ë¦¬ì— í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ìœ í†µê¸°í•œìœ¼ë¡œ íŒë‹¨
            if min_distance < DISTANCE_THRESHOLD:
                type_confidence = 1.0 # ì‹ ë¢°ë„ 1.0 ë¶€ì—¬
                if closest_keyword_block and closest_keyword_block not in filtered_word_blocks:
                    filtered_word_blocks.append(closest_keyword_block)
            elif best_date > date.today(): # ìœ í†µê¸°í•œ í‚¤ì›Œë“œê°€ ì—†ì§€ë§Œ ë‚ ì§œ í˜•íƒœê°€ ìˆê³  ë¯¸ë˜ì¸ ê²½ìš°
                type_confidence = 0.8 # ì‹ ë¢°ë„ 0.8 ë¶€ì—¬
            break  # ìµœì¢… ë‚ ì§œë¥¼ ì°¾ìœ¼ë©´ ì¢…ë£Œ

    return {
        'extracted_date': best_date,                                     # ìµœì¢… ë‚ ì§œ
        'date_recognition_confidence': round(recognition_confidence, 4), # ìœ í†µê¸°í•œ ì¸ì‹ ì‹ ë¢°ë„
        'date_type_confidence': type_confidence,                         # ì°¾ì€ ê¸€ìê°€ ìœ í†µê¸°í•œì´ ë§ëŠ”ê°€?ì— ëŒ€í•œ ì‹ ë¢°ë„ (ìœ í†µê¸°í•œ ìœ í˜• ì‹ ë¢°ë„)
        'raw_ocr_text': raw_text,                                        # OCRë¡œ ì¸ì‹í•œ ëª¨ë“  í…ìŠ¤íŠ¸
        'filtered_word_blocks': filtered_word_blocks,                    # OCRë¡œ ì¸ì‹í•œ í…ìŠ¤íŠ¸ ì¤‘ ìœ í†µê¸°í•œ í›„ë³´ ê´€ë ¨
    }

# 4-3. Word2Vecì„ ì´ìš©í•œ ìƒ‰ì¬ë£Œëª… ì¶”ì¶œ
def extract_product_name(raw_text: str, yolo_category: str, all_word_blocks: List[Dict[str, Any]]) -> Dict[str, Any]:
    model = SrmappConfig.word_embedding_model
    ANCHOR_WORD = 'ì‹ì¬ë£Œ'       # 'ì‹ì¬ë£Œ' ë‹¨ì–´ì™€ì˜ ìœ ì‚¬ì„± íŒë‹¨
    SIMILARITY_THRESHOLD = 0.5  # Word Embedding ìœ ì‚¬ë„ ì„ê³„ê°’

    if model is None:
        return {'name': 'Word Embedding Model Not Loaded', 'similarity': 0.0}

    if ANCHOR_WORD not in model.wv:      # ê¸°ì¤€ ë‹¨ì–´('ì‹ì¬ë£Œ')ê°€ ëª¨ë¸ ë‹¨ì–´ì¥ì— ìˆëŠ”ì§€ í™•ì¸
        print(f"ğŸš¨ Anchor word '{ANCHOR_WORD}' not in Word Embedding vocabulary. Extraction failed.")
        return {'name': 'Anchor Word Missing', 'similarity': 0.0}

    valid_words = []

    for target_block in all_word_blocks:  # ì‹ì¬ë£Œëª…ê³¼ ë¬´ê´€í•œ ì˜ì–‘ì„±ë¶„ ê´€ë ¨ ë‚´ìš© ì œì™¸
        if not target_block['text']: continue
        is_nutrition_value = False
        text_height = abs(target_block['bounds'][0][1] - target_block['bounds'][2][1])
        SEARCH_RADIUS = text_height * 3

        is_numeric_like = re.match(r'[\d\.\,]+[gmkcal%]', target_block['text'], re.IGNORECASE)

        if is_numeric_like:
            for block in all_word_blocks:
                if block == target_block: continue
                if any(keyword in block['text'] for keyword in NUTRITION_KEYWORDS):
                    if calculate_distance(target_block, block) < SEARCH_RADIUS:
                        is_nutrition_value = True
                        break

        if not is_nutrition_value:
            word = re.sub(r'[^ê°€-í£a-zA-Z]', '', target_block['text'])
            if len(word) > 1 and word in model.wv and word != ANCHOR_WORD:          # ë‹¨ì–´ ê¸¸ì´ê°€ 1 ì´ˆê³¼ì´ê³ , ëª¨ë¸ ë‹¨ì–´ì¥ì— ì¡´ì¬í•˜ë©°, ê¸°ì¤€ ë‹¨ì–´ì™€ ë™ì¼í•˜ì§€ ì•Šì€ ë‹¨ì–´ë§Œ í›„ë³´ë¡œ
                valid_words.append(word)

    if not valid_words: # OCRì—ì„œ ìœ íš¨í•œ ë‹¨ì–´ë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš°
        return {'name': None, 'similarity': 0.0}

    best_match = None     # ì›Œë“œ ì„ë² ë”© ìœ ì‚¬ë„ ë¹„êµ
    max_similarity = -1

    for word in set(valid_words):
        try:
            similarity = model.wv.similarity(ANCHOR_WORD, word)
            if similarity > max_similarity:
                max_similarity = similarity
                best_match = word
        except Exception as e:
            print(f"Similarity calculation error: {e}")
            continue

    if best_match and max_similarity >= SIMILARITY_THRESHOLD: #ìµœì¢… ê²°ê³¼ ë°˜í™˜
        final_confidence = round(max_similarity, 4)

        print(
            f"âœ… Product Name Found via Word Embedding: {best_match} (Similarity: {max_similarity:.2f}, Final Conf: {final_confidence:.2f})")
        return {'name': best_match, 'similarity': final_confidence}

    else: # ìœ ì‚¬ë„ê°€ ì„ê³„ê°’ì„ ë„˜ì§€ ëª»í•˜ê±°ë‚˜ ë§¤ì¹­ë˜ëŠ” ë‹¨ì–´ê°€ ì—†ëŠ” ê²½ìš°
        print(
            f"âš ï¸ Word Embedding failed (Similarity < {SIMILARITY_THRESHOLD}). Returning None.")
        return {'name': None, 'similarity': 0.0}

    # 5. ê²°ê³¼ í†µí•© ë° ì‹ ë¢°ë„ ë¶„ê¸° ì²˜ë¦¬
def integrate_results(base_data: Dict[str, Any], yolo_result: Dict[str, Any], ocr_info: Dict[str, Any],
                      ocr_raw_output: Dict[str, Any]) -> Dict[str, Any]:

    yolo_category = yolo_result.get('category_name', 'ì‹ì¬ë£Œ ë¯¸í™•ì¸')  # YOLOë¡œ ì¸ì‹í•œ ì‹ì¬ë£Œëª…
    yolo_confidence = yolo_result.get('confidence', None)
    determined_ingredient_name = yolo_category

    raw_ocr_text = ocr_info.get('raw_ocr_text', '')  # OCRë¡œ ì¸ì‹í•œ ëª¨ë“  í…ìŠ¤íŠ¸

    all_word_blocks = ocr_raw_output.get('word_blocks', [])  #
    product_result = extract_product_name(raw_ocr_text, yolo_category, all_word_blocks) #

    final_product_name = product_result['name']                           #
    product_similarity_score = product_result['similarity']               #

    recognition_conf = ocr_info.get('date_recognition_confidence', 0.0)  # ìœ í†µê¸°í•œ ì¸ì‹ ì‹ ë¢°ë„
    type_conf = ocr_info.get('date_type_confidence', 0.0)  # ìœ í†µê¸°í•œ ìœ í˜• ì‹ ë¢°ë„
    extracted_date = ocr_info.get('extracted_date')  # ìœ í†µê¸°í•œ í‘œê¸° í˜•íƒœ í†µì¼

    YOLO_CONFIDENCE_THRESHOLD = 0.7 # YOLO ì‹ ë¢°ë„ ì„ê³„ê°’
    PRODUCT_SIMILARITY_THRESHOLD = 0.65  # ì œí’ˆëª… ì¶”ì¶œ ìµœì¢… ì„ê³„ê°’ (ìœ ì‚¬ë„ ê¸°ë°˜)

    # ìµœì¢… ì‹ì¬ë£Œëª… ì„ ì • (ìš°ì„ ìˆœìœ„: OCR ê³ ìœ ì‚¬ë„ > YOLO íƒì§€ > ì €ìœ ì‚¬ë„ YOLO ì´ˆê¸°ê°’)
    if product_similarity_score >= PRODUCT_SIMILARITY_THRESHOLD: # OCR ìœ ì‚¬ë„ê°€ ë†’ì„ë•Œ
        determined_ingredient_name = final_product_name
    elif yolo_category not in ['FALLBACK_MODE', 'ì‹ì¬ë£Œ ë¯¸í™•ì¸'] and yolo_confidence >= YOLO_CONFIDENCE_THRESHOLD: # YOLO ê²°ê³¼ë¥¼ ì‹ ë¢°í•  ìˆ˜ ìˆì„ ë•Œ
        determined_ingredient_name = yolo_category
    else: # ê·¸ ì™¸ì˜ ê²½ìš° (ì‹ì¬ë£Œ ë¯¸í™•ì¸)
        determined_ingredient_name = 'ì‹ì¬ë£Œ ë¯¸í™•ì¸'

    # ìœ í†µê¸°í•œ ìµœì¢…
    RECOGNITION_THRESHOLD = 0.85  # ìœ í†µê¸°í•œ ì¸ì‹ ì‹ ë¢°ë„ ì„ê³„ê°’
    TYPE_THRESHOLD = 0.75         # ìœ í†µê¸°í•œ ìœ í˜• ì‹ ë¢°ë„ ì„ê³„ê°’

    expiry_date_status = 'NOT_FOUND'

    if extracted_date:  # ìœ íš¨í•œ ë‚ ì§œê°€ ì¸ì‹ëœ ê²½ìš°
        if recognition_conf >= RECOGNITION_THRESHOLD and type_conf >= TYPE_THRESHOLD: # ì‹ ë¢°ë„ ê¸°ë°˜ ìƒíƒœ ê²°ì •
            expiry_date_status = 'CONFIRMED'  # ì‹ ë¢°ë„ ë†’ìŒ
        else:
            expiry_date_status = 'UNCERTAIN'  # ì‹ ë¢°ë„ ë‚®ìŒ

        if extracted_date < date.today():   # ë§Œë£Œ ì—¬ë¶€ ì²´í¬ (ì‹ ë¢°ë„ì™€ ë¬´ê´€)
            expiry_date_status = 'EXPIRED'  # ë§Œë£Œë¨

    final_data = {
        'user_id': base_data['user_id'],  # ì‚¬ìš©ì ì•„ì´ë””

        'ingredient_pic': base_data['ingredient_pic'],          # ì¸í’‹ ì‚¬ì§„
        'stored_at': base_data['stored_at'],                    # ì €ì¥ ì¼ì‹œ

        'ingredient_name': determined_ingredient_name,          # ìµœì¢… ê²°ì •ëœ ì‹ì¬ë£Œëª…

        'category_yolo': yolo_category,                         # YOLO ì¸ì‹ ê²°ê³¼
        'yolo_confidence': yolo_confidence,                     # YOLO ì¸ì‹ ì‹ ë¢°ë„

        'product_name_ocr': final_product_name,                 # OCR ì¸ì‹ ì‹ì¬ë£Œëª… (Word Embedding ê²°ê³¼)
        'product_similarity_score': product_similarity_score,   # OCR ì‹ì¬ë£Œëª…ê³¼ 'ì‹ì¬ë£Œ' ì•µì»¤ ì›Œë“œ ê°„ì˜ ìœ ì‚¬ë„ ì ìˆ˜ (ë°˜ì˜¬ë¦¼ëœ ê°’)

        'expiry_date': extracted_date,                          # ìœ í†µê¸°í•œ
        'expiry_date_status': expiry_date_status,               # ìœ í†µê¸°í•œ ìƒíƒœ (ë§Œë£Œ ì—¬ë¶€)
        'date_recognition_confidence': recognition_conf,        # ìœ í†µê¸°í•œ ì¸ì‹ ì‹ ë¢°ë„
        'date_type_confidence': type_conf,                      # ìœ í†µê¸°í•œ ìœ í˜• ì‹ ë¢°ë„

        'raw_ocr_text': raw_ocr_text,                           # OCR ì „ì²´ í…ìŠ¤íŠ¸ (ë””ë²„ê¹…ìš©)
        'ocr_word_blocks': ocr_info.get('filtered_word_blocks') # OCR ìœ í†µê¸°í•œ ê´€ë ¨ í…ìŠ¤íŠ¸ (ë””ë²„ê¹…ìš©)
    }

    return final_data