# XndApp/Services/pipeline_logic.py

import os
import numpy as np
import cv2
from django.conf import settings
from typing import Dict, List, Any
from XndApp.apps import SrmappConfig
from google.cloud import vision
import re
from datetime import date
import math

# 1. ë©”ì¸ íŒŒì´í”„ë¼ì¸ í•¨ìˆ˜
def process_image_pipeline(user_id: int, image_path: str) -> Dict[str, Any]:
    if not os.path.exists(image_path):
        return {"error": "Image file not found"}

    result_data = {
        'user_id': user_id,
        'stored_at': date.today(),
        'ingredient_name': '',
        'category_yolo': None,
        'product_name_ocr': None,
        'expiry_date': None,
        'expiry_date_status': 'NOT_FOUND',
        'ingredient_pic': image_path,
    }

    # 1. YOLO ì‹¤í–‰: BB ì¢Œí‘œ ë° ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ
    yolo_result = run_yolo_detection(image_path)

    # ğŸ’¡ Fallback ë¡œì§: YOLO ì‹¤íŒ¨(None ë°˜í™˜) ì‹œ ì „ì²´ ì´ë¯¸ì§€ OCRì„ ì‹œë„í•˜ë„ë¡ yolo_result ë®ì–´ì“°ê¸°
    if yolo_result is None:
        yolo_result = {
            'bounding_box': [0, 0, 0, 0],
            'category_name': 'FALLBACK_MODE',
            'fallback_mode': True  # Fallback ëª¨ë“œ í”Œë˜ê·¸
        }

    ocr_raw_output = run_ocr(image_path, yolo_result)     # 2. OCR ì‹¤í–‰: ì´ë¯¸ì§€ í¬ë¡­ í›„, í´ë¼ìš°ë“œ API í˜¸ì¶œ ë° ì›ë³¸ í…ìŠ¤íŠ¸ ìˆ˜ì‹ 
    ocr_info = extract_ocr_info(ocr_raw_output)           # 3. í…ìŠ¤íŠ¸ ì •ë³´ ì¶”ì¶œ: ì›ë³¸ í…ìŠ¤íŠ¸ì—ì„œ ë‚ ì§œ, ì œí’ˆëª… ë“±ì„ ì •ê·œì‹ìœ¼ë¡œ ì¶”ì¶œ
    final_data = integrate_results(result_data, yolo_result, ocr_info)     # 4. ê²°ê³¼ í†µí•©: YOLOì™€ OCR ê²°ê³¼ë¥¼ ë³‘í•©í•˜ê³  ì‹ ë¢°ë„ì— ë”°ë¼ ë¶„ê¸° ì²˜ë¦¬

    return final_data

# 2. â‘¡ YOLO ëª¨ë¸ ì ìš© (ê°ì²´ íƒì§€)
def run_yolo_detection(image_path: str) -> Dict[str, Any]:
    model = SrmappConfig.yolo_model

    if model is None:
        return None  # ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ ì‹œ None ë°˜í™˜

    try:
        results = model.predict(source=image_path, conf=0.25, iou=0.5, verbose=True)

        if not results or not results[0].boxes:
            return None  # íƒì§€ ì‹¤íŒ¨ ì‹œ None ë°˜í™˜

        ## ê°ì²´ ì¸ì‹ ì„±ê³µ ì‹œ
        box = results[0].boxes[0]
        xmin, ymin, xmax, ymax = map(int, box.xyxy[0].tolist())
        confidence = float(box.conf[0])
        class_index = int(box.cls[0])
        category_name = model.names[class_index]

        ## YOLO ê²°ê³¼ ì‹œê°í™” ë° ì €ì¥
        img_array = np.fromfile(image_path, np.uint8)
        image_cv = cv2.imdecode(img_array, cv2.IMREAD_COLOR)
        cv2.rectangle(image_cv, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)
        text = f"{category_name}: {confidence:.2f}"
        cv2.putText(image_cv, text, (xmin, ymin - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)
        base_name = os.path.splitext(os.path.basename(image_path))[0]
        output_filename = f"{base_name}_yolo_checked.jpg"
        output_path = settings.MEDIA_ROOT / 'stored_images_yolo' / output_filename
        os.makedirs(settings.MEDIA_ROOT / 'stored_images_yolo', exist_ok=True)

        is_success, buffer = cv2.imencode(".jpg", image_cv)
        if is_success:
            buffer.tofile(output_path)
            print(f"âœ… YOLO visualization saved to: {output_path}")

        return {
            'category_name': category_name,
            'confidence': confidence,
            'bounding_box': [xmin, ymin, xmax, ymax],
        }

    except Exception as e:
        print(f"YOLO detection error: {e}")
        return None  # ì˜ˆì™¸ ë°œìƒ ì‹œ None ë°˜í™˜


# 3. â‘¢ OCR ëª¨ë¸ ì ìš© (ì´ë¯¸ì§€ í¬ë¡­ ë° í…ìŠ¤íŠ¸ ì¸ì‹)
def run_ocr(image_path: str, yolo_result: Dict[str, Any]) -> Dict[str, Any]:

    word_blocks: List[Dict[str, Any]] = []

    try:  #êµ¬ê¸€ API ì¸ì¦ ì„¤ì •
        os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = str(settings.GOOGLE_APPLICATION_CREDENTIALS)
    except AttributeError:
        return {'raw_text': "Error: GOOGLE_APPLICATION_CREDENTIALS is not set in settings.py",
                'word_blocks': word_blocks}

    try:
        img_array = np.fromfile(image_path, np.uint8)
        image_cv = cv2.imdecode(img_array, cv2.IMREAD_COLOR)
    except Exception as e:
        return {"raw_text": f"Error: Image read failed. {e}", 'word_blocks': word_blocks}


    if yolo_result.get('fallback_mode'): #Fallback ëª¨ë“œ : ì´ë¯¸ì§€ ì „ì²´ ì‚¬ìš©
        # Fallback ëª¨ë“œ: ì´ë¯¸ì§€ ì „ì²´ë¥¼ BBë¡œ ì‚¬ìš©
        height, width = image_cv.shape[:2]
        xmin, ymin, xmax, ymax = 0, 0, width, height
    else: # YOLOê°€ íƒì§€í•œ BBë°•ìŠ¤ ì‚¬ìš©
        bounding_box = yolo_result.get('bounding_box', [0, 0, 0, 0])
        xmin, ymin, xmax, ymax = bounding_box

    base_name = os.path.splitext(os.path.basename(image_path))[0]
    ocr_output_dir = settings.MEDIA_ROOT / 'stored_images_ocr'
    os.makedirs(ocr_output_dir, exist_ok=True)

    try:
        cropped_image = image_cv[ymin:ymax, xmin:xmax] #OpenCV ì´ë¯¸ì§€ ì²˜ë¦¬

        is_success, buffer = cv2.imencode(".png", cropped_image) # Cropëœ ì´ë¯¸ì§€ ì¸ì½”ë”©
        if not is_success:
            return {'raw_text': "Error: Image encoding failed", 'word_blocks': word_blocks}

        image_bytes = buffer.tobytes()

        client = vision.ImageAnnotatorClient()         # Vision API í˜¸ì¶œ
        image = vision.Image(content=image_bytes)      # ë°ì´í„° ì¶”ì¶œ

        image_context = vision.ImageContext(language_hints=["ko"])

        response = client.annotate_image(
            request={
                'image': image,
                'features': [{'type_': vision.Feature.Type.DOCUMENT_TEXT_DETECTION}],
                'image_context': image_context
            }
        )

        raw_text = "" # OCRë¡œ ì½ì€ ëª¨ë“  í…ìŠ¤íŠ¸
        if response.full_text_annotation:
            raw_text = response.full_text_annotation.text

            document = response.full_text_annotation
            for page in document.pages:
                for block in page.blocks:
                    for paragraph in block.paragraphs:
                        for word in paragraph.words:
                            word_text = ''.join([symbol.text for symbol in word.symbols])
                            word_blocks.append({
                                'text': word_text,
                                'confidence': word.confidence,
                                'bounds': [(v.x, v.y) for v in word.bounding_box.vertices]
                            })

            # OCR ì‹œê°í™”
            ocr_bb_image = cropped_image.copy()
            for block_data in word_blocks:
                bounds = block_data['bounds']
                x1, y1 = bounds[0]
                x2, y2 = bounds[2]

                cv2.rectangle(ocr_bb_image, (x1, y1), (x2, y2), (0, 165, 255), 1)
                cv2.putText(ocr_bb_image, block_data['text'], (x1, y1 - 2),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.35, (255, 255, 255), 1)

            ocr_bb_filename = f"{base_name}_ocr_bb_checked.jpg"
            ocr_bb_path = ocr_output_dir / ocr_bb_filename

            is_success_bb, buffer_bb = cv2.imencode(".jpg", ocr_bb_image)
            if is_success_bb:
                buffer_bb.tofile(ocr_bb_path)
                print(f"âœ… OCR BB visualization saved to: {ocr_bb_path}")

            return {'raw_text': raw_text, 'word_blocks': word_blocks}

        return {'raw_text': '', 'word_blocks': word_blocks}

    except Exception as e:
        print(f"OCR API or Image processing error: {e}")
        return {"raw_text": f"OCR API or Processing error: {e}", 'word_blocks': word_blocks}


# â‘£ ì •ë³´ ì¶”ì¶œ ë° ê°€ê³µ
# 4-1. ìœ í†µê¸°í•œ

# ìœ í†µê¸°í•œ í…ìŠ¤íŠ¸ íƒì§€
DATE_PATTERNS = [
    r'(?:ì†Œë¹„ê¸°í•œ|ìœ í†µê¸°í•œ)\s*[:]?\s*(\d{4})[ë…„./-]\s*(\d{1,2})[ì›”./-]\s*(\d{1,2})[ì¼]?(?:\s+\d{2}:\d{2}(?::\d{2})?)?[.]?', #ì†Œë¹„/ìœ í†µê¸°í•œ : YYYYë…„ MMì›” DDì¼
    r'(\d{4})ë…„\s*(\d{1,2})ì›”\s*(\d{1,2})ì¼(?:\s+\d{2}:\d{2}(?::\d{2})?)?[.]?',  # YYYYë…„ MMì›” DDì¼
    r'(\d{2})ë…„\s*(\d{1,2})ì›”\s*(\d{1,2})ì¼(?:\s+\d{2}:\d{2}(?::\d{2})?)?[.]?',  # YYë…„ MMì›” DDì¼
    r'(\d{4})[ë…„./-]\s*(\d{1,2})[ì›”./-]\s*(\d{1,2})[ì¼]?\s*ê¹Œì§€(?:\s+\d{2}:\d{2}(?::\d{2})?)?[.]?', #YYYYë…„ MMì›” DDì¼ê¹Œì§€
    r'(\d{4})[./-]([01]?\d)[./-]([0-3]?\d)(?:\s+\d{2}:\d{2}(?::\d{2})?)?[.]?',  # YYYY.MM.DD
    r'(\d{2})[./-]([01]?\d)[./-]([0-3]?\d)(?:\s+\d{2}:\d{2}(?::\d{2})?)?[.]?',  # YY.MM.DD
    r'(\d{4})(\d{2})(\d{2})(?:\s+\d{2}:\d{2}(?::\d{2})?)?[.]?',              # YYYYMMDD
    r'(\d{2})(\d{2})(\d{2})(?:\s+\d{2}:\d{2}(?::\d{2})?)?[.]?',              # YYMMDD
    r'([01]?\d)[./]([0-3]?\d)[.]?'                                       # MM.DD
]

# í…ìŠ¤íŠ¸ ë¸”ë¡ ì‚¬ì´ì˜ ê±°ë¦¬ ê³„ì‚° (ë‹¨ì–´ - ìˆ«ì)
def get_center(bounds: List[tuple]) -> tuple:
    """ ê²½ê³„ ìƒì(bounds)ì˜ ì¤‘ì‹¬ì  ì¢Œí‘œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. """
    x_coords = [v[0] for v in bounds]
    y_coords = [v[1] for v in bounds]
    center_x = sum(x_coords) / len(x_coords)
    center_y = sum(y_coords) / len(y_coords)
    return (center_x, center_y)

def calculate_distance(block1: Dict, block2: Dict) -> float:
    center1 = get_center(block1['bounds'])
    center2 = get_center(block2['bounds'])
    return math.sqrt((center1[0] - center2[0]) ** 2 + (center1[1] - center2[1]) ** 2)


# 4. í…ìŠ¤íŠ¸ ì •ë³´ ì¶”ì¶œ (ìœ í†µê¸°í•œ, ì œí’ˆëª…)
def extract_ocr_info(ocr_raw_output: Dict[str, Any]) -> Dict[str, Any]:
    raw_text = ocr_raw_output.get('raw_text', '')
    word_blocks = ocr_raw_output.get('word_blocks', [])

    NUTRITION_KEYWORDS = ['ë‚˜íŠ¸ë¥¨', 'íƒ„ìˆ˜í™”ë¬¼', 'ë‹¹ë¥˜', 'ì§€ë°©', 'íŠ¸ëœìŠ¤ì§€ë°©', 'í¬í™”ì§€ë°©', 'ì½œë ˆìŠ¤í…Œë¡¤', 'ë‹¨ë°±ì§ˆ', 'ì¹¼ìŠ˜', 'ì—´ëŸ‰', 'g', 'mg', 'kcal', '%']  #ì˜ì–‘ì„±ë¶„ í‚¤ì›Œë“œ (ìœ í†µê¸°í•œ í›„ë³´ì—ì„œ íƒˆë½)
    INDICATOR_KEYWORDS = ['ê¹Œì§€', 'ê¸°í•œ', 'ìœ í†µ', 'ì†Œë¹„', 'ìœ í†µê¸°í•œ', 'ì†Œë¹„ê¸°í•œ'] # ìœ í†µê¸°í•œ í‚¤ì›Œë“œ (ìœ í†µê¸°í•œ ìœ í˜• ì‹ ë¢°ë„ 1.0 ë¶€ì—¬)

    found_dates_info = []
    found_keywords_info = []

    # ë‚ ì§œ í›„ë³´ ë° í‚¤ì›Œë“œ ìˆ˜ì§‘
    for block in word_blocks:
        if any(keyword in block['text'] for keyword in INDICATOR_KEYWORDS):
            found_keywords_info.append(block)

        for pattern in DATE_PATTERNS:
            match = re.search(pattern, block['text'])
            if match:
                date_parts = list(match.groups())
                try:
                    parsed_date = None
                    if len(date_parts) == 3:
                        year, month, day = map(int, date_parts)
                        if year < 100: year += 2000
                        parsed_date = date(year, month, day)
                    elif len(date_parts) == 2:
                        month, day = map(int, date_parts)
                        today = date.today()
                        current_year_date = date(today.year, month, day)
                        parsed_date = date(today.year + 1, month,
                                           day) if current_year_date < today else current_year_date

                    if parsed_date and 2000 <= parsed_date.year <= 2999:
                        found_dates_info.append((parsed_date, block))
                        break
                except ValueError:
                    continue

    best_date = None
    recognition_confidence = 0.0
    type_confidence = 0.5
    filtered_word_blocks = []

    if found_dates_info:
        sorted_dates = sorted(found_dates_info, key=lambda item: item[0], reverse=True)

        for candidate_date, date_block in sorted_dates:
            is_nutrition_info = False
            text_height = abs(date_block['bounds'][0][1] - date_block['bounds'][2][1])
            SEARCH_RADIUS = text_height * 3  # ë‚ ì§œ í…ìŠ¤íŠ¸ ë†’ì´ì˜ 3ë°° ë°˜ê²½ì„ 'ì£¼ë³€'ìœ¼ë¡œ ì •ì˜

            # ë‚ ì§œ ê°™ì•„ ë³´ì´ëŠ” ìˆ«ì ì£¼ë³€ì— ì˜ì–‘ì„±ë¶„ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´, ë‚ ì§œê°€ ì•„ë‹Œ ì˜ì–‘ì„±ë¶„ ê°’ìœ¼ë¡œ ì¸ì‹
            for block in word_blocks:
                if block == date_block: continue

                if any(keyword in block['text'] for keyword in NUTRITION_KEYWORDS):
                    if calculate_distance(date_block, block) < SEARCH_RADIUS:
                        is_nutrition_info = True
                        break
            if is_nutrition_info: # ì˜ì–‘ ì •ë³´ë¡œ íŒë‹¨ë˜ë©´ ë‹¤ìŒ ë‚ ì§œ í›„ë³´ë¡œ
                continue

            best_date = candidate_date   # ìœ íš¨í•œ ë‚ ì§œ í›„ë³´ë¥¼ ì°¾ìœ¼ë©´ ìµœì¢… ì„ íƒ
            best_date_block = date_block
            recognition_confidence = best_date_block['confidence'] # ìœ í†µê¸°í•œ ê¸€ìì˜ OCR ì¸ì‹ ì‹ ë¢°ë„
            filtered_word_blocks.append(best_date_block)

            # ì°¾ì€ ì •ë³´ê°€ ìœ í†µê¸°í•œì´ ë§ëŠ”ì§€ì— ëŒ€í•œ ì‹ ë¢°ë„
            min_distance = float('inf')
            closest_keyword_block = None
            if found_keywords_info:
                for keyword_block in found_keywords_info:
                    distance = calculate_distance(date_block, keyword_block)
                    if distance < min_distance:
                        min_distance = distance
                        closest_keyword_block = keyword_block

            DISTANCE_THRESHOLD = text_height * 5 # ê¸€ì ë†’ì´ì˜ 5ë°° ì´ë‚´ ê±°ë¦¬ì— í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ìœ í†µê¸°í•œìœ¼ë¡œ íŒë‹¨
            if min_distance < DISTANCE_THRESHOLD:
                type_confidence = 1.0 # ì‹ ë¢°ë„ 1.0 ë¶€ì—¬
                if closest_keyword_block and closest_keyword_block not in filtered_word_blocks:
                    filtered_word_blocks.append(closest_keyword_block)
            elif best_date > date.today(): # í‚¤ì›Œë“œê°€ ì—†ì§€ë§Œ ë‚ ì§œ í˜•íƒœê°€ ìˆê³  ë¯¸ë˜ì¸ ê²½ìš°
                type_confidence = 0.8 # ì‹ ë¢°ë„ 0.8 ë¶€ì—¬

            break  # ìµœì¢… ë‚ ì§œë¥¼ ì°¾ìœ¼ë©´ ì¢…ë£Œ

    product_name = 'ì œí’ˆëª… ì¶”ì¶œ ì‹¤íŒ¨'  # ì¶”í›„ ì¶”ê°€

    return {
        'product_name': product_name,
        'extracted_date': best_date,
        'date_recognition_confidence': round(recognition_confidence, 4),
        'date_type_confidence': type_confidence,
        'raw_ocr_text': raw_text,
        'filtered_word_blocks': filtered_word_blocks
    }

# 5. ê²°ê³¼ í†µí•© ë° ì‹ ë¢°ë„ ë¶„ê¸° ì²˜ë¦¬
def integrate_results(base_data: Dict[str, Any], yolo_result: Dict[str, Any], ocr_info: Dict[str, Any]) -> Dict[
    str, Any]:
    # 1. ê¸°ë³¸ ì •ë³´ ë³‘í•©
    base_data['category_yolo'] = yolo_result.get('category_name') # YOLOë¡œ íŒŒì•…í•œ ì‹ì¬ë£Œ ì¹´í…Œê³ ë¦¬
    base_data['product_name_ocr'] = ocr_info.get('product_name') # OCRë¡œ íŒŒì•…í•œ ì‹ì¬ë£Œëª…
    base_data['raw_ocr_text'] = ocr_info.get('raw_ocr_text')  # OCRë¡œ íŒŒì•…í•œ í…ìŠ¤íŠ¸ ì •ë³´ (ë””ë²„ê¹…ìš©)
    base_data['date_recognition_confidence'] = ocr_info.get('date_recognition_confidence', 0.0) # ìœ í†µê¸°í•œ ì¸ì‹ ì‹ ë¢°ë„
    base_data['date_type_confidence'] = ocr_info.get('date_type_confidence', 0.0) # ì£¼ì–´ì§„ ì •ë³´ê°€ ìœ í†µê¸°í•œì¸ì§€ì— ëŒ€í•œ ì‹ ë¢°ë„
    base_data['ocr_word_blocks'] = ocr_info.get('filtered_word_blocks')  # OCRë¡œ íŒŒì•…í•œ ìœ í†µê¸°í•œ ê´€ë ¨ ë‹¨ì–´ ëª©ë¡ ë° ì‹ ë¢°ë„

    final_name = ocr_info.get('product_name') or yolo_result.get('category_name') # ì‹ì¬ë£Œ ì´ë¦„ ê²°ì •
    if final_name in ['FALLBACK_MODE', None, 'ì œí’ˆëª… ì¶”ì¶œ ì‹¤íŒ¨']:
        final_name = 'ì‹ì¬ë£Œ ë¯¸í™•ì¸'
    base_data['ingredient_name'] = final_name

    # ìœ í†µê¸°í•œ ì‹ ë¢°ë„ ì²˜ë¦¬
    recognition_conf = ocr_info.get('date_recognition_confidence', 0.0)
    type_conf = ocr_info.get('date_type_confidence', 0.0)
    extracted_date = ocr_info.get('extracted_date')
    RECOGNITION_THRESHOLD = 0.85  # ìˆ«ì ì¸ì‹ ì‹ ë¢°ë„ ì„ê³„ê°’
    TYPE_THRESHOLD = 0.75  # ìœ í˜• ì‹ ë¢°ë„ ì„ê³„ê°’

    base_data['expiry_date'] = extracted_date

    if extracted_date:
        if extracted_date < date.today():
            base_data['expiry_date_status'] = 'EXPIRED'   # ìœ í†µê¸°í•œì´ ê³¼ê±° ë‚ ì§œì¸ ê²½ìš°
        elif recognition_conf >= RECOGNITION_THRESHOLD and type_conf >= TYPE_THRESHOLD:
            base_data['expiry_date_status'] = 'CONFIRMED' # ìœ í†µê¸°í•œ ì¸ì‹, ì •ë³´ ìœ í˜• ì‹ ë¢°ë„ ëª¨ë‘ ì„ê³„ê°’ ì´ìƒì¸ ê²½ìš°
            base_data['raw_ocr_text'] = None
        else:
            base_data['expiry_date_status'] = 'UNCERTAIN' # ìœ í†µê¸°í•œ ì¸ì‹ ë˜ëŠ” ìœ í˜• ì‹ ë¢°ë„ ì¤‘ í•˜ë‚˜ ì´ìƒ ì„ê³„ê°’ ë¯¸ë§Œì¸ ê²½ìš°
    else:
        base_data['expiry_date_status'] = 'NOT_FOUND' # ë‚ ì§œë¥¼ ì•„ì˜ˆ ì°¾ì§€ ëª»í•œ ê²½ìš°

    return base_data
